---
title: "Assignment 1 — Matching Pennies: Strategies, Tournament, and Stan"
author: "Ramona"
format:
  html:
    toc: true
    number-sections: true
---

Repository link: https://github.com/ramona-tanovic/ACM.git

## Game protocol (course version)

Agents play 60 trials total:
- 30 trials, then **swap roles**, then 30 more.
- If you are **Matcher**: win (+1) when actions match, else −1.
- If you are **Hider**: win (+1) when actions differ, else −1.

## Strategies and cognitive constraints

We implement two stan strategies plus one more 50/50 strategy for comparison.
Crucially, the tournament is run **on Stan models**: the parametric strategies sample their parameters from Stan priors, so each simulated “agent” is an instantiation of a Stan cognitive model.

### Strategy 1: Random(0.5)

No memory, no learning. Robust but not exploitative.

### Strategy 2: WSLS(Stan) — probabilistic WSLS policy

WSLS uses one-step memory (previous action + previous outcome). Here it is a *parametric policy*:

- After a win: repeat previous action with probability \(p_{\text{repeat|win}}\)
- After a loss: repeat previous action with probability \(p_{\text{repeat|loss}}\)
- With probability `lapse`, behavior mixes with random choice (0.5)

Cognitive constraints:
- 1-step memory; limited inference (no opponent model); lapses capture noise.

### Strategy 3: ForgetfulBias(Stan) — bounded-memory bias tracker

Tracks opponent’s tendency to play “1” using a single estimate \(\hat p\) with forgetting rate \(\eta\), then best-responds by role.

Cognitive constraints:
- compressed memory (one scalar); assumes stationary marginal bias; lapses capture noise.

## Stan step 1: priors used to spawn agents (tournament on Stan models)

We sample parameters from priors in Stan:
- WSLS prior over \(p_{\text{repeat|win}}, p_{\text{repeat|loss}}, lapse\)
- ForgetfulBias prior over \(\eta, lapse\)

These draws are then used to spawn agents in the tournament.

```{r stan_priors, fig.cap="Stan prior summaries used to spawn tournament agents."}
knitr::include_graphics(file.path("figs","stan_prior_params.png"))
```

## Simulation workflow

We run a full tournament across all strategy pairs with the role-swap protocol, then summarize performance.

```{r simulation}
library(readr)
library(dplyr)

trials <- read_csv(file.path("data","processed","trials.csv"), show_col_types = FALSE)
summary_final <- read_csv(file.path("data","processed","summary_final.csv"), show_col_types = FALSE)
summary_blocks <- read_csv(file.path("data","processed","summary_blocks.csv"), show_col_types = FALSE)

dplyr::glimpse(trials)
```

## Results: tournament performance

### Mean cumulative payoff (role swap marker)

```{r r1, fig.cap="Mean cumulative payoff across matchups. Dashed line marks role swap after trial 30."}
knitr::include_graphics(file.path("figs","mean_cum_payoff.png"))
```

Brief interpretation:
- Random vs Random stays near 0 (no structure to exploit).
- WSLS(Stan) can exploit opponents that become predictable.
- ForgetfulBias(Stan) can do well against biased opponents, but if the opponent is history-dependent it can be exploited.

### Block-wise totals (trials 1–30 vs 31–60)

```{r r2, fig.cap="Mean block payoff by matchup. Block 1: A=Matcher. Block 2: A=Hider."}
knitr::include_graphics(file.path("figs","block_heatmap.png"))
```

### Mean total payoff by matchup (60 trials)

```{r r3, fig.cap="Mean total payoff (A) by matchup over 60 trials."}
knitr::include_graphics(file.path("figs","final_heatmap.png"))
```

### Distribution of total payoffs

```{r r4, fig.cap="Distribution of total payoff over 60 trials by strategy (A), aggregated across opponents."}
knitr::include_graphics(file.path("figs","final_distribution.png"))
```

## Stan step 2: fitting a policy model to behavior

After generating behavior, we fit a Stan policy model (repeat-after-win/loss + lapse) to sequences from **A vs Random(0.5)**. This provides an interpretable posterior summary of how each strategy behaves.

```{r fit}
stan_sum <- read_csv(file.path("data","processed","stan_policy_summary.csv"), show_col_types = FALSE)

stan_sum %>%
  select(strategy, variable, mean, q5, q95) %>%
  knitr::kable(digits = 3, caption = "Stan posterior summary (mean and 90% interval).")
```

```{r fit_plot, fig.cap="Stan posterior means and 90% intervals for inferred policy parameters."}
knitr::include_graphics(file.path("figs","stan_policy_params.png"))
```

## Conclusion

The tournament compares strategies under the role-swap protocol, and the Stan components make the cognitive modelling explicit:
1) strategies are instantiated with parameters sampled from Stan priors (tournament on Stan models),
2) behaviour is summarized by fitting a policy model in Stan to recover interpretable parameters.
