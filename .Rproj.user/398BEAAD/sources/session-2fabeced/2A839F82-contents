---
title: "Assignment 1 — Matching Pennies: two cognitive strategies, role swap, and interpretation"
author: "Ramona"
format: html
execute:
  echo: false
  warning: false
  message: false
---

## What this assignment is doing

The Matching Pennies game is a simple setting where we can write down explicit *strategy hypotheses* and then test what they imply.

This report focuses on two strategies from the course notes:

- WSLS (Win–Stay / Lose–Shift), an "immediate reaction" strategy.
- k-ToM, a strategy that explicitly models the opponent rather than only reacting.

We simulate many independent matches and report uncertainty (bootstrap intervals) rather than only point estimates.

Course inspiration (strategies + cognitive constraints): https://fusaroli.github.io/AdvancedCognitiveModeling2023/building-verbal-models-of-the-matching-pennies-game.html

## Game and protocol (including the role swap)

- The game repeats for **T = 60 trials**.
- Each trial, one player is the **Matcher** (wants actions to match) and one is the **Mismatcher** (wants actions to differ).
- Midway through the match (**after 30 trials**) the roles swap.

Why the role swap matters cognitively:

If we only report a final pay-off, we mostly measure "who exploited whom". The role swap adds a second diagnostic axis: *flexibility when the reward contingency flips*. A role-sensitive strategy should adjust quickly when becoming Matcher vs Mismatcher, whereas a strategy that does not represent the task structure may show asymmetric performance across halves.

## Strategy 1: WSLS (Win–Stay / Lose–Shift)

### Verbal description

WSLS uses the last outcome as feedback:

- After a win: tend to repeat the previous action ("stay").
- After a loss: tend to change to the other action ("shift").

We implement a probabilistic WSLS with an explicit error process:

- p_repeat_win: probability of repeating after a win
- p_repeat_loss: probability of repeating after a loss
- lapse: probability of ignoring the rule and responding randomly

### Formalization diagram

```{mermaid}
flowchart TD
  A[Trial t] --> B{t == 1?}
  B -->|yes| C[Choose 0/1 with 0.5]
  B -->|no| D{Won at t-1?}
  D -->|win| E[Repeat previous action with p_repeat_win]
  D -->|loss| F[Repeat previous action with p_repeat_loss]
  E --> G[Otherwise switch]
  F --> G
  G --> H{Lapse?}
  H -->|yes| I[Random 0/1]
  H -->|no| J[Use intended action]
  J --> K[Observe opponent + outcome]
  I --> K
  K --> L[Store last action + last win]
```

### Cognitive constraints

WSLS is cognitively simple by design:

- Memory: only needs the previous action and whether it won ("memory of 1").
- Perseveration: encoded via "win-stay".
- Errors / exploration: encoded via lapse and probabilistic stay/shift.

## Strategy 2: k-ToM (interpretable opponent-modelling)

### Verbal description

Rather than only reacting to reward, k-ToM makes an explicit model of the opponent. To keep the model interpretable (and not a black box), we implement this as **belief learning** + **noisy best response**:

- Maintain a belief b_opp = P(opponent plays action 1)
- Update b_opp with a delta rule (learning rate alpha)
- Choose the best response given the current role (Matcher vs Mismatcher)
- Use beta (decision sharpness) + lapse to model noise

### Formalization diagram

```{mermaid}
flowchart TD
  A[Initialize belief b_opp = 0.5] --> B[Trial t]
  B --> C[Compute best response given role]
  C --> D[Convert to choice prob via beta]
  D --> E{Lapse?}
  E -->|yes| F[Random 0/1]
  E -->|no| G[Sample action]
  F --> H[Observe opponent action]
  G --> H
  H --> I[Update belief: b_opp <- b_opp + alpha*(opp - b_opp)]
  I --> B
```

### Cognitive constraints

- Memory limitation / forgetting: alpha controls recency weighting (higher alpha = shorter effective memory).
- Errors: lapse captures random deviations; beta captures graded noisiness rather than deterministic rules.
- Task structure: the role (Matcher/Mismatcher) explicitly enters the decision rule, so we expect clearer adjustment after the role swap.

## Results

### Fig 1 — Tournament performance (with uncertainty)

This shows the mean final payoff for player A in each ordered pairing (A vs B), with a bootstrap 95% interval.

```{r}
knitr::include_graphics("outputs/figs/fig1_matchups.png")
```

What this plot allows you to understand:

- Whether one strategy systematically exploits the other (mean payoff far from 0).
- Whether that advantage is stable across simulations (narrow vs wide intervals).

### Fig 2 — Role sensitivity: advantage as Matcher

This aggregates over *both* player positions (A and B). For each strategy, we compute:

Payoff-as-Matcher minus Payoff-as-Mismatcher.

```{r}
knitr::include_graphics("outputs/figs/fig2_role_advantage.png")
```

What this plot allows you to understand:

- Whether a strategy is symmetric across roles, or systematically better as Matcher or Mismatcher.
- Whether role differences are strong enough to survive uncertainty.

### Fig 3 — Interpretation plot: repeat probabilities after win/loss

This is the main mechanistic plot.

It estimates, for each strategy and each half of the match:

- P(repeat next action | previous trial was a win)
- P(repeat next action | previous trial was a loss)

```{r}
knitr::include_graphics("outputs/figs/fig3_repeat_signature.png")
```

What this plot allows you to understand:

- WSLS should show a clear asymmetry: high repeat after win, low repeat after loss.
- k-ToM can produce different (often more graded) patterns, because it is responding to *beliefs about the opponent*, not only reward.
- If the pattern changes across halves, that is evidence that the role swap changes the inferred dynamics (a cognitive signature, not just score).

### Fig 4 — Payoff distributions

This makes variability visible: even if means are near 0, some matchups may be high-variance.

```{r}
knitr::include_graphics("outputs/figs/fig4_payoff_distribution.png")
```

## Key tables

```{r}
library(readr)
library(dplyr)

matchup_sum <- read_csv("outputs/data/matchup_summary.csv", show_col_types = FALSE)
role_sum    <- read_csv("outputs/data/role_advantage_summary.csv", show_col_types = FALSE)
sig_sum     <- read_csv("outputs/data/repeat_signature_summary.csv", show_col_types = FALSE)

matchup_sum |> arrange(desc(mean))
```

```{r}
role_sum |> arrange(desc(mean))
```

```{r}
sig_sum |> arrange(strategy, half, condition)
```

## Short conclusion template

Across repeated Matching Pennies, WSLS and k-ToM can differ even when average payoffs are similar: the role swap reveals whether strategies represent the task structure, and the repeat-after-win/loss signatures make the underlying mechanism visible (reactive reinforcement vs belief-guided best response).
